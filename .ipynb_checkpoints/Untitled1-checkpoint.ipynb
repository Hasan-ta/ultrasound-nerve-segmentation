{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from skimage.io import imsave, imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_path = '../raw/'\n",
    "\n",
    "image_rows = 420\n",
    "image_cols = 580\n",
    "\n",
    "mean = np.load('train_mean.npy')\n",
    "std = np.load('train_std.npy')\n",
    "\n",
    "\n",
    "def create_train_data():\n",
    "    train_data_path = os.path.join(data_path, 'train')\n",
    "    images = os.listdir(train_data_path)\n",
    "    total = len(images) / 2\n",
    "\n",
    "    imgs = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "    imgs_mask = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating training images...')\n",
    "    print('-'*30)\n",
    "    for image_name in images:\n",
    "        if 'mask' in image_name:\n",
    "            continue\n",
    "        image_mask_name = image_name.split('.')[0] + '_mask.tif'\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_grey=True)\n",
    "        img_mask = imread(os.path.join(train_data_path, image_mask_name), as_grey=True)\n",
    "\n",
    "        img = np.array([img])\n",
    "        img_mask = np.array([img_mask])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_mask[i] = img_mask\n",
    "        print(img.shape)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    \n",
    "    \n",
    "    imgs_train, imgs_val, imgs_mask_train, imgs_mask_val = train_test_split(imgs, imgs_mask, test_size=0.15, random_state=42)\n",
    "\n",
    "    np.save('imgs_train.npy', imgs_train)\n",
    "    np.save('imgs_mask_train.npy', imgs_mask_train)\n",
    "    np.save('imgs_val.npy',imgs_val)\n",
    "    np.save('imgs_mask_val.npy',imgs_mask_val)\n",
    "    \n",
    "    print('Loading done.')\n",
    "    print('Saving to .npy files done.')\n",
    "\n",
    "\n",
    "def load_train_data():\n",
    "    imgs_train = np.load('imgs_train.npy')\n",
    "    imgs_mask_train = np.load('imgs_mask_train.npy')\n",
    "    return imgs_train, imgs_mask_train\n",
    "\n",
    "def load_val_data():\n",
    "    imgs_val = np.load('imgs_val.npy')\n",
    "    imgs_mask_val = np.load('imgs_mask_val.npy')\n",
    "    return imgs_val, imgs_mask_val\n",
    "\n",
    "\n",
    "def create_test_data():\n",
    "    train_data_path = os.path.join(data_path, 'test')\n",
    "    images = os.listdir(train_data_path)\n",
    "    total = len(images)\n",
    "\n",
    "    imgs = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "    imgs_id = np.ndarray((total, ), dtype=np.int32)\n",
    "\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating test images...')\n",
    "    print('-'*30)\n",
    "    for image_name in images:\n",
    "        img_id = int(image_name.split('.')[0])\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_grey=True)\n",
    "\n",
    "        img = np.array([img])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_id[i] = img_id\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Loading done.')\n",
    "\n",
    "    np.save('imgs_test.npy', imgs)\n",
    "    np.save('imgs_id_test.npy', imgs_id)\n",
    "    print('Saving to .npy files done.')\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    imgs_test = np.load('imgs_test.npy')\n",
    "    imgs_id = np.load('imgs_id_test.npy')\n",
    "    return imgs_test, imgs_id\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ''''''\n",
    "    #create_train_data()\n",
    "    #create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from skimage.transform import resize as skresize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, UpSampling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import skimage\n",
    "\n",
    "#from data import load_train_data, load_test_data\n",
    "\n",
    "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
    "\n",
    "img_rows = 96\n",
    "img_cols = 96\n",
    "\n",
    "smooth = 1.\n",
    "X_train = 0; X_val = 0; y_train = 0; y_val = 0;\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = skimage.transform.resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n",
    "\n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p\n",
    "\n",
    "\n",
    "def get_unet():\n",
    "    inputs = Input((img_rows, img_cols, 1))\n",
    "    start = 128; act = 'relu'\n",
    "    conv1 = Conv2D(start, (3, 3), activation=act, padding='same')(inputs)\n",
    "    conv1 = Conv2D(start, (3, 3), activation=act, padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    #pool1 = Dropout(0.5)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(start*2, (3, 3), activation=act, padding='same')(pool1)\n",
    "    conv2 = Conv2D(start*2, (3, 3), activation=act, padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #pool2 = Dropout(0.5)(pool2)\n",
    "\n",
    "    conv3 = Conv2D(start*4, (3, 3), activation=act, padding='same')(pool2)\n",
    "    conv3 = Conv2D(start*4, (3, 3), activation=act, padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    #pool3 = Dropout(0.5)(pool3)\n",
    "\n",
    "    conv4 = Conv2D(start*8, (3, 3), activation=act, padding='same')(pool3)\n",
    "    conv4 = Conv2D(start*8, (3, 3), activation=act, padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    #pool4 = Dropout(0.5)(pool4)\n",
    "\n",
    "    conv5 = Conv2D(start*16, (3, 3), activation=act, padding='same')(pool4)\n",
    "    conv5 = Conv2D(start*16, (3, 3), activation=act, padding='same')(conv5)\n",
    "    #conv5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(start*8, (3, 3), activation=act, padding='same')(up6)\n",
    "    conv6 = Conv2D(start*8, (3, 3), activation=act, padding='same')(conv6)\n",
    "    #conv6 = Dropout(0.5)(conv6)\n",
    "    \n",
    "\n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(start*4, (3, 3), activation=act, padding='same')(up7)\n",
    "    conv7 = Conv2D(start*4, (3, 3), activation=act, padding='same')(conv7)\n",
    "    #conv7 = Dropout(0.5)(conv7)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(start*2, (3, 3), activation=act, padding='same')(up8)\n",
    "    conv8 = Conv2D(start*2, (3, 3), activation=act, padding='same')(conv8)\n",
    "    #conv8 = Dropout(0.5)(conv8)\n",
    "\n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(start, (3, 3), activation=act, padding='same')(up9)\n",
    "    conv9 = Conv2D(start, (3, 3), activation=act, padding='same')(conv9)\n",
    "    #conv9 = Dropout(0.5)(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def combine_generator(gen1, gen2):\n",
    "    while True:\n",
    "        yield(gen1.next(), gen2.next())\n",
    "\n",
    "\n",
    "def train_and_predict():\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-'*30)\n",
    "    imgs_train, imgs_mask_train = load_train_data()\n",
    "    imgs_val, imgs_mask_val = load_val_data()\n",
    "\n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    "    imgs_val = preprocess(imgs_val)\n",
    "    imgs_mask_val = preprocess(imgs_mask_val)\n",
    "\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    maximum = np.amax(imgs_train[:])\n",
    "    print(\"maximum: {0}\".format(maximum))\n",
    "    minimum = np.amin(imgs_train[:])\n",
    "    print(\"minimum: {0}\".format(minimum))\n",
    "    #imgs_train = imgs_train/maximum;\n",
    "    \n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "    #imgs_train -= mean\n",
    "    #imgs_train /=- std\n",
    "\n",
    "    imgs_val = imgs_val.astype('float32')\n",
    "    #imgs_val = imgs_val/maximum\n",
    "    #imgs_val -= mean\n",
    "    #imgs_val /= std\n",
    "    \n",
    "    np.save('train_mean.npy',mean)\n",
    "    np.save('train_std.npy',std)\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    "\n",
    "    imgs_mask_val = imgs_mask_val.astype('float32')\n",
    "    imgs_mask_val /= 255.  # scale masks to [0, 1]\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "\n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='loss', save_best_only=True)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0.003, patience=3, verbose=0, mode='min')\n",
    "\n",
    "    data_gen_args = dict(featurewise_center=False,\n",
    "                     featurewise_std_normalization=False,\n",
    "                     rotation_range=90.,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.2)\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "    seed = 1\n",
    "    image_datagen.fit(imgs_train, augment=True, seed=seed)\n",
    "    mask_datagen.fit(imgs_mask_train, augment=True, seed=seed)\n",
    "\n",
    "    image_generator = image_datagen.flow(imgs_train, batch_size=4, seed=seed, shuffle=True)\n",
    "    mask_generator = mask_datagen.flow(imgs_mask_train, batch_size=4, seed=seed, shuffle=True)\n",
    "\n",
    "    train_generator = combine_generator(image_generator, mask_generator)\n",
    "    \n",
    "    #train_generator = data_augmentation_engine(imgs_train, imgs_mask_train, batch_size = 4)\n",
    "    \n",
    "    #datagen = CustomImageDataGenerator(zoom_range=(0.9,1.1),\n",
    "    #                               horizontal_flip=True,\n",
    "    #                               vertical_flip=False, \n",
    "#                                           rotation_range=5,\n",
    "    #                               channel_shift_range=5.0,\n",
    "    #                               elastic=None #(100, 20)\n",
    "    #                               )\n",
    "\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "\n",
    "\n",
    "    #model.fit_generator(\n",
    "    #    train_generator,\n",
    "    #    steps_per_epoch=20000,\n",
    "    #    epochs=30,\n",
    "    #    validation_data=(imgs_val,imgs_mask_val),\n",
    "    #    callbacks=[model_checkpoint,early_stop])\n",
    "\n",
    "    model.fit(imgs_train, imgs_mask_train, batch_size=32, nb_epoch=30, verbose=1, shuffle=True,\n",
    "              validation_data=(imgs_val,imgs_mask_val),\n",
    "              callbacks=[model_checkpoint,early_stop])\n",
    "    \n",
    "    #        #fit\n",
    "    #model.fit_generator(datagen.flow(imgs_train, imgs_mask_train, batch_size=4),\n",
    "    #                samples_per_epoch=20000,\n",
    "    #                epochs=50,\n",
    "    #                verbose=1,\n",
    "    #                callbacks=[model_checkpoint, early_stop],\n",
    "    #                validation_data=(imgs_val, imgs_mask_val)\n",
    "    #                )\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-'*30)\n",
    "    imgs_test, imgs_id_test = load_test_data()\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-'*30)\n",
    "    model.load_weights('weights.h5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "    imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Saving predicted masks to files...')\n",
    "    print('-' * 30)\n",
    "    pred_dir = 'preds'\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "    for image, image_id in zip(imgs_mask_test, imgs_id_test):\n",
    "        image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "        imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ''''''\n",
    "    #train_and_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "model = get_unet()\n",
    "model.load_weights('weights.h5')\n",
    "\n",
    "imgs_val, imgs_mask_val = load_val_data()\n",
    "imgs_val = preprocess(imgs_val)\n",
    "imgs_mask_val = preprocess(imgs_mask_val)\n",
    "\n",
    "imgs_mask_val = imgs_mask_val.astype('float32')\n",
    "imgs_mask_val /= 255.  # scale masks to [0, 1]\n",
    "\n",
    "\n",
    "mean = np.load('train_mean.npy')\n",
    "std = np.load('train_std.npy')\n",
    "\n",
    "imgs_val = imgs_val.astype('float32')\n",
    "#imgs_val = imgs_val/255.0\n",
    "#imgs_val -= mean\n",
    "#imgs_val /= std\n",
    "\n",
    "y_val_pred = model.predict(imgs_val, verbose=1)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from JSAnimation import IPython_display\n",
    "%matplotlib inline\n",
    "\n",
    "original_val, temp = load_val_data()\n",
    "original_val = preprocess(original_val)\n",
    "\n",
    "nx = 300\n",
    "ny = 300\n",
    "\n",
    "fig = plt.figure()\n",
    "data = np.zeros((nx, ny))\n",
    "im = plt.imshow(data, cmap='gist_gray_r', vmin=0, vmax=1)\n",
    "\n",
    "def init():\n",
    "    im.set_data(np.zeros((nx, ny)))\n",
    "\n",
    "def animate(i):\n",
    "    mask = cv2.Canny((y_val_pred[i]*255).astype(np.uint8), 100, 200)\n",
    "    y_val_th = cv2.Canny((imgs_mask_val[i]*255).astype(np.uint8), 100, 200)\n",
    "    \n",
    "    xx = cv2.cvtColor(original_val[i], cv2.COLOR_GRAY2RGB)\n",
    "    # Red is true Blue is prediction\n",
    "    xx[np.where((mask[:,:]>0.5))[0],np.where((mask[:,:]>0.5))[1],2] = 255;\n",
    "    xx[np.where((mask[:,:]>0.5))[0],np.where((mask[:,:]>0.5))[1],1] = 0;\n",
    "    xx[np.where((mask[:,:]>0.5))[0],np.where((mask[:,:]>0.5))[1],0] = 0;\n",
    "    \n",
    "    xx[np.where((y_val_th>0.5))[0],np.where((y_val_th>0.5))[1],2] = 0;\n",
    "    xx[np.where((y_val_th>0.5))[0],np.where((y_val_th>0.5))[1],1] = 0;\n",
    "    xx[np.where((y_val_th>0.5))[0],np.where((y_val_th>0.5))[1],0] = 255;\n",
    "    xx = cv2.resize(xx,(300,300))\n",
    "    \n",
    "    im.set_data(xx)\n",
    "    return im\n",
    "\n",
    "animation.FuncAnimation(fig, animate, init_func=init, frames=200,\n",
    "                               interval=1000)\n",
    "\n",
    "\n",
    "#for i,mask in enumerate(y_val_pred):\n",
    "\n",
    "    \n",
    "    #cv2.addWeighted(xx, 0.5, (a/255).astype(np.float32), 0.5, 0.2, xx)\n",
    "    #cv2.addWeighted(xx, .5, (b/255).astype(np.float32), 0.5, 0.2, xx)\n",
    "    \n",
    "    #xx = cv2.cvtColor(xx,cv2.COLOR_RGB2BGR)\n",
    "    #cv2.imshow('image',xx)\n",
    "    #cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
